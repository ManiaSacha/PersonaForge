# PersonaForge ğŸš€

[![FastAPI](https://img.shields.io/badge/FastAPI-0.110.0-green?logo=fastapi)](https://fastapi.tiangolo.com/)
[![Python](https://img.shields.io/badge/Python-3.10+-blue?logo=python)](https://www.python.org/)
[![Gradio](https://img.shields.io/badge/Gradio-5.0+-orange?logo=gradio)](https://gradio.app/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Open Source Love](https://badges.frapsoft.com/os/v1/open-source.svg?v=103)](https://github.com/ManiaSacha/PersonaForge)

---

> **PersonaForge** is a modular platform for building, managing, and running AI personas with Retrieval-Augmented Generation (RAG), LLMs, and multi-persona orchestration. Perfect for research, prototyping, and production AI applications.

---

## âœ¨ Features

- âš¡ **FastAPI Backend** â€” blazing fast, modern Python API
- ğŸ–¥ï¸ **Gradio UI** â€” clean, interactive frontend for creating and interacting with personas
- ğŸ§  **Persona Profiles** â€” define, save, and load persona JSON schemas
- ğŸ“ **Prompt Engine** â€” generate persona-customized prompts for LLMs
- ğŸ’¾ **Disk Persistence** â€” all personas are saved as JSON for easy sharing
- ğŸ”Œ **RAG & Vector DB Ready** â€” upload and embed documents for context-aware responses
- ğŸ¤– **AI-to-AI Chat** â€” let two personas have conversations with each other
- ğŸ“Š **Persona Versioning** â€” track changes to personas with automatic backups
- ğŸ“œ **Memory Logs** â€” save all interactions with timestamps for analysis
- ğŸ“¦ **Export Feature** â€” download persona configs and chat logs as JSON
- ğŸ”„ **Multiple LLM Support** â€” use llava, gemma3, llama3.2, gemma:2b, tinyllama, and more
- ğŸ”’ **Extensible** â€” add new persona types, prompt templates, and LLMs easily

## ğŸ“‚ Project Structure

```
PersonaForge/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py               # FastAPI entry point
â”‚   â”œâ”€â”€ persona_profiles/     # Persona JSON definitions
â”‚   â”œâ”€â”€ logs/                # Chat history logs (JSONL)
â”‚   â”œâ”€â”€ prompt_engine.py      # Prompt generation utility
â”‚   â””â”€â”€ persona_storage.py    # Persona versioning and logs
â”œâ”€â”€ rag_db/                   # Vector database for RAG
â”œâ”€â”€ ui.py                     # Gradio UI frontend
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md
```

## ğŸš€ Quickstart

1. **Clone the repo:**
   ```bash
   git clone https://github.com/ManiaSacha/PersonaForge.git
   cd PersonaForge
   ```
2. **Create a virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```
3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
4. **Run the FastAPI backend server:**
   ```bash
   uvicorn backend.main:app --reload --port 8100
   ```
5. **Run the Gradio UI frontend** (in a separate terminal):
   ```bash
   python ui.py
   ```
6. **Access the UI:**
   - Visit [http://127.0.0.1:7860](http://127.0.0.1:7860) for the Gradio UI
   - Visit [http://localhost:8100/docs](http://localhost:8100/docs) for the API docs

## ğŸ› ï¸ Usage

### Using the Gradio UI

- **Create a Persona:**
  - Go to the "Create Persona" tab
  - Fill in the name, tone, domain, goals, and response style
  - Click "Create Persona"

- **Ask a Persona:**
  - Go to the "Ask Persona" tab
  - Enter the persona name and your question
  - Select a model (llava, gemma3, llama3.2, gemma:2b, tinyllama)
  - Click "Ask" to get a response

- **Upload Knowledge:**
  - Go to the "Upload Knowledge" tab
  - Enter the persona name and upload PDF, TXT, or MD files
  - Click "Upload & Embed" to add knowledge to the persona

- **AI-to-AI Chat:**
  - Go to the "AI-to-AI Chat" tab
  - Enter two persona names, an opening message, and select rounds
  - Click "Start Conversation" to watch them talk to each other

- **Export Persona:**
  - Go to the "Export Persona" tab
  - Enter the persona name and click "Download Export"
  - Get a JSON file with the persona config and chat history

### Using the API

- **Create a Persona:**
  - Use `POST /persona/` to save a new persona
- **Ask a Persona:**
  - Use `POST /ask_persona/` with name, question, and model
- **Upload Documents:**
  - Use `POST /upload_doc/` to add knowledge to a persona
- **AI-to-AI Chat:**
  - Use `POST /persona_chat/` to start a conversation between personas
- **Export Persona Data:**
  - Use `GET /export_persona/{name}` to download persona data

## ğŸŒŸ Example Persona JSON
```json
{
  "name": "LegalAdvisorGPT",
  "tone": "Formal",
  "domain": "Corporate Law",
  "goals": [
    "Review contracts",
    "Identify legal risks",
    "Summarize compliance requirements"
  ],
  "response_style": "Legal, structured, bullet-pointed"
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please open issues and pull requests for improvements or new features.

1. Fork the repo
2. Create your feature branch (`git checkout -b feature/my-feature`)
3. Commit your changes (`git commit -am 'Add new feature'`)
4. Push to the branch (`git push origin feature/my-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

> Made with â¤ï¸ by [ManiaSacha](https://github.com/ManiaSacha)


A platform for building, managing, and running AI personas with RAG and LLM integration.

## Folder Structure

```
PersonaForge/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py               â† FastAPI entry point
â”‚   â””â”€â”€ persona_profiles/     â† Persona definitions
â”œâ”€â”€ data/                     â† Documents to embed for RAG
â”œâ”€â”€ models/                   â† Any fine-tuned models or checkpoints
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
```

## Quickstart

1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
2. Run the FastAPI server:
   ```bash
   uvicorn backend.main:app --reload
   ```
3. Visit http://localhost:8000/docs to test the API.
